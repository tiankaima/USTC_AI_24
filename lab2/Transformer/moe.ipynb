{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T02:51:46.927955Z",
     "start_time": "2024-06-22T02:51:46.919365Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import List\n",
    "\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLao8DKovBQe"
   },
   "source": [
    "## Tokenization\n",
    "\n",
    "### 简介\n",
    "\n",
    "Tokenization 的主要目的是将文本分解成更小的单位(Tokens)，减小模型输入数据的内在结构复杂度(从句子变为单词序列)，从而简化模型训练的难度。同时将字符的序列转化为 Token 序号的序列，便于模型输入。\n",
    "\n",
    "Tokenization 首先确定语言的词表划分粒度，一般可分为：\n",
    "\n",
    "-   字符级：将文本分解为字符。\n",
    "-   单词级：将文本分解为单词。\n",
    "-   子词级：将单词进一步分解为更小的有意义单元（如前缀、后缀）。\n",
    "\n",
    "之后使用预定义的规则来识别 tokens, 或使用统计或机器学习技术来识别最优的 token 切分方式。例如，BPE（Byte Pair Encoding）或 SentencePiece。\n",
    "\n",
    "最后实现一组文本序列和 Tokens 序列之间相互转化的函数，即可完成 Tokenization 部分。\n",
    "\n",
    "### 实验要求\n",
    "\n",
    "1. 实现字符级切分的简单 tokenizer， 由 字符表， 字符到 token 的 encoder()函数 和 token 到字符的 decoder() 函数组成。\n",
    "2. 调用 现有的 tokenizer 实现，比如 openai 的 tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T02:51:46.988217Z",
     "start_time": "2024-06-22T02:51:46.979940Z"
    },
    "id": "EgEOwXJ1vBQf"
   },
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    def __init__(self, dataPath: str):\n",
    "        with open(dataPath, \"r\", encoding=\"utf-8\") as f:\n",
    "            self.dataset = f.read()\n",
    "        self.char2index = {}\n",
    "        self.index2char = {}\n",
    "        self.generate_vocabulary()\n",
    "\n",
    "    def generate_vocabulary(self):\n",
    "        index = 0\n",
    "        for char in self.dataset:\n",
    "            if char not in self.char2index:\n",
    "                self.char2index[char] = index\n",
    "                self.index2char[index] = char\n",
    "                index += 1\n",
    "\n",
    "    def encode(self, sentence: str) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        例子, 假设A-Z 对应的token是1-26, 句子开始，结束符号的token是0。\n",
    "        input  : \"ABCD\"\n",
    "        output : Tensor([0,1,2,3])\n",
    "\n",
    "        注意: 为了后续实验方便，输出Tensor的数据类型dtype 为torch.long。\n",
    "        \"\"\"\n",
    "        return torch.tensor(\n",
    "            [self.char2index[char] for char in sentence], dtype=torch.long\n",
    "        )\n",
    "\n",
    "    def decode(self, tokens: torch.Tensor) -> str:\n",
    "        \"\"\"\n",
    "        例子, 假设A-Z 对应的token是1-26, 句子开始，结束符号的token是0。\n",
    "        input : Tensor([0,1,2,3])\n",
    "        output : \"ABCD\"\n",
    "        \"\"\"\n",
    "        return \"\".join([self.index2char[index] for index in tokens])\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(dataPath=\"input.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvbipIfAvBQf"
   },
   "source": [
    "### 定义 dataloader 和 dataset\n",
    "\n",
    "为了高效加载数据，我们需要把输入文件接入 PyTorch 的数据加载器中。在这里我们定义 `ShakespeareDataset` 类用于加载数据集，用 PyTorch 的 `DataLoader` 类来实现数据加载。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T02:51:47.075160Z",
     "start_time": "2024-06-22T02:51:46.995045Z"
    },
    "id": "T5cfV2kMvBQf"
   },
   "outputs": [],
   "source": [
    "class ShakespeareDataset(Dataset):\n",
    "    def __init__(self, filepath, tokenizer, chunk_size):\n",
    "        self.tokenizer = tokenizer\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "            text = file.read()\n",
    "        text = text[: int(len(text) / 20)]\n",
    "        self.encoded = self.tokenizer.encode(text)\n",
    "        self.chunk_size = chunk_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded) - self.chunk_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        chunk = self.encoded[idx: idx + self.chunk_size]\n",
    "        label = self.encoded[idx + 1: idx + self.chunk_size + 1]\n",
    "\n",
    "        return chunk, label\n",
    "\n",
    "\n",
    "def create_dataloader(filepath, tokenizer, chunk_size, batch_size, shuffle=True):\n",
    "    dataset = ShakespeareDataset(filepath, tokenizer, chunk_size)\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        dataset, [int(len(dataset) * 0.8), len(dataset) - int(len(dataset) * 0.8)]\n",
    "    )\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mg9d9W_UvBQf"
   },
   "source": [
    "注意力的计算公式为：\n",
    "\n",
    "$$\n",
    "Head = Attention(x)=Softmax(M\\cdot QK^T)V\\\\\n",
    "Q=xW_{q},K=xW_{k}, V=xW_{v}\n",
    "$$\n",
    "\n",
    "这里实现的一些数学技巧可以参见 attention.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T02:51:47.098514Z",
     "start_time": "2024-06-22T02:51:47.087226Z"
    },
    "id": "iHI-eCKFvBQf"
   },
   "outputs": [],
   "source": [
    "class HeadAttention(nn.Module):\n",
    "    def __init__(self, seq_len: int, embed_size: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.register_buffer(\"tril\", torch.tril(torch.ones(seq_len, seq_len)))\n",
    "        self.to_q = nn.Linear(embed_size, hidden_size)\n",
    "        self.to_k = nn.Linear(embed_size, hidden_size)\n",
    "        self.to_v = nn.Linear(embed_size, hidden_size)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.to_q.weight)\n",
    "        nn.init.xavier_uniform_(self.to_k.weight)\n",
    "        nn.init.xavier_uniform_(self.to_v.weight)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        inputs.to(device)\n",
    "        Q = self.to_q(inputs)\n",
    "        K = self.to_k(inputs)\n",
    "        V = self.to_v(inputs)\n",
    "        Attention = torch.matmul(Q, K.transpose(-2, -1)) / (K.size(-1) ** 0.5)\n",
    "        Attention = Attention.masked_fill(self.tril == 0, float(\"-inf\"))\n",
    "        Attention = F.softmax(Attention, dim=-1)\n",
    "        Attention = torch.matmul(Attention, V).to(inputs.device)\n",
    "        return Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AsVWVtiUvBQg"
   },
   "source": [
    "Transformer 中使用的注意力机制时会使用多个注意力头，期望每个注意力头能够注意到不同的信息。\n",
    "所以实际公式需要修改如下\n",
    "\n",
    "$$\n",
    "MultiHeadAttention(x)=[Head_0, Head_1,...,Head_h]W_o\\\\\n",
    "Head_i = Attention(x)=Softmax(M\\cdot Q_iK_i^T)V_i\\\\\n",
    "Q_i=xW_{iq},K=xW_{ik}, V=xW_{iv}\n",
    "$$\n",
    "\n",
    "在搭建网络的过程中，同学们可能会用到 nn.ModuleList 这个库，每个$Head_i$的计算可以直接使用上面已经实现的单头注意力计算。\n",
    "最后对于这些注意力头再使用一个简单的线性层/矩阵$W_o$汇总信息即可\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T02:51:47.127277Z",
     "start_time": "2024-06-22T02:51:47.110288Z"
    },
    "id": "WS5NY6TbvBQg"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, n_heads: int, head_size: int, seq_len: int, embed_size: int):\n",
    "        super().__init__()\n",
    "        head_size = embed_size // n_heads\n",
    "        self.heads = nn.ModuleList(\n",
    "            [HeadAttention(seq_len, embed_size, head_size) for _ in range(n_heads)]\n",
    "        )\n",
    "        self.projection = nn.Linear(embed_size, embed_size)\n",
    "        nn.init.xavier_uniform_(self.projection.weight)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs.to(device)\n",
    "        head_outputs = [head(inputs) for head in self.heads]\n",
    "        MHAttention = torch.cat(head_outputs, dim=-1)\n",
    "        MHAttention = self.projection(MHAttention).to(inputs.device)\n",
    "        return MHAttention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQhoHEJ_vBQg"
   },
   "source": [
    "## 专家网络 Expert\n",
    "\n",
    "Expert 即为标准 Transformer 中的 FeedForward 模块。\n",
    "\n",
    "在经过 MultiHeadAttention 模块后，seq_len 中的每一个 Embedding 都对应了前文信息的加权求和。在经过 FeedForward 模块时，模型对每一个位置的 Embedding 进行了两次线性变换和一次非线性变换，可以视为对当前语境下的信息进行加工。知识编辑的一些研究表明，FeedForword 模块参数包含了大量的事实性知识。\n",
    "\n",
    "一个直观的想法是，类比于 MultiHeadAttention，我们在每一层训练多个 FeedForward 模块，对于不同位置的 Embedding 使用不同的 FeedForward 模块处理对应的信息。就好像每层有多个 Expert,每个 Expert 都负责处理一类数据的深加工，因此我们称 FeedForward 为 Expert。\n",
    "\n",
    "实现方面:\n",
    "\n",
    "FeedForward 层由两层简单的线性层组成，对于一个(batch_size, seq_len, embed_size)输入的向量 x\n",
    "只在最后一个维度上进行计算，以实现词的特征维度上的交互(注意力机制是词之间的交互)。\n",
    "其首先用一个线性层将 x 最后一维扩大至原先 4 倍，然后继续用一个线性层还原回原先的维度。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T02:51:47.145530Z",
     "start_time": "2024-06-22T02:51:47.133369Z"
    },
    "id": "Q0U_WYPCvBQg"
   },
   "outputs": [],
   "source": [
    "class Expert(nn.Module):\n",
    "    def __init__(self, embed_size: int):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(embed_size, embed_size * 4)\n",
    "        self.fc2 = nn.Linear(embed_size * 4, embed_size)\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs.to(device)\n",
    "        mid = F.relu(self.fc1(inputs))\n",
    "        outputs = self.fc2(mid).to(inputs.device)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHcYkH9ivBQg"
   },
   "source": [
    "## 选通网络 TopkRouter\n",
    "\n",
    "在实现了单个 Expert 后，我们要设计一个选通网络决策每个 Embedding 要使用那个 Expert 计算\n",
    "\n",
    "### 为了说明选通网络的实现方式，我们定义一下记号：\n",
    "\n",
    "inputs.shape = [batch_size, seq_len, embed_size] = [1, 8, 16]\n",
    "\n",
    "即输入有 batch_size=1 个数据点，该数据有 seq_len 长度的 context，即包含 seq_len=8 个 Embedding，每个 Embedding 长度为 embed_dim=16。\n",
    "\n",
    "记 num_expert = 4, 即该层包含 num_expert 个并列的 Expert。\n",
    "\n",
    "记 active_expert = 2, 即计算每个 Embedding 仅有 active_expert 个 Expert 参与计算。\n",
    "\n",
    "### 选通网络计算\n",
    "\n",
    "对于有 seq_len=8 的数据，如果每个 Expert 都参与计算每一个 Embedding，那么一共需要计算 seq_len\\*embed_size = 32 次， 这极大的增加了模型计算量，因此我们往往只激活其中的 active_experts 个 Expert，这要求我们对每一个 Embedding 计算最合适的 active_experts 个 Expert。\n",
    "\n",
    "对于单个 Expert 的原版 Transformer 来说：\n",
    "\n",
    "$$\n",
    "outputs[0,seq] = FeedForward(inputs[0,seq])\n",
    "$$\n",
    "\n",
    "对于多个 Expert 的网络：\n",
    "\n",
    "$$\n",
    "outputs[0,seq] = \\sum_{i \\in range(num\\_model)} \\alpha_{i} Expert_{i}(inputs[0,seq])\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\alpha_{i} = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "    1 & Expert_{i}  \\text{is selected} \\\\\n",
    "    0 & Expert_{i}  \\text{is not selected} \\\\\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "将$\\{\\alpha_0,\\alpha_1,\\dots,\\alpha_{num_experts-1}\\}$记为向量$\\alpha$:\n",
    "\n",
    "$$\n",
    "outputs[0,seq] = \\alpha \\cdot \\{Expert_i(inputs[0,seq])\\}\n",
    "$$\n",
    "\n",
    "一个选通 0,2 号 Expert 的$\\alpha$的例子是$[1,0,1,0]$\n",
    "\n",
    "问题在于如何求得 $\\alpha$, 对于一个 Embedding ，我们使用神经网络对每个 Expert 打分，在根据分数计算$\\alpha$\n",
    "\n",
    "$$\n",
    "score[0,seq] = MLP(inputs[0,seq])  \\\\\n",
    "\\alpha = topK(score[0,seq])\n",
    "$$\n",
    "\n",
    "例如：\n",
    "\n",
    "$$\n",
    "score[0,seq] = [11.32,1.54,14.83,-1.90] \\\\\n",
    "\\alpha = [1,0,1,0]\n",
    "$$\n",
    "\n",
    "从优化的角度来说，$\\alpha$取前 k 大的分数的下标（即 argmax），这个操作是不可导的，这里我们用之前在\"attention.ipynb\"中提到的技巧处理这里的计算。\n",
    "\n",
    "$$\n",
    "mask(score[0,seq]) = [11.32,-inf,14.83,-inf] \\\\\n",
    "\\alpha = softmax(mask(score[0,seq])) = [0.028,0,0.971,0] \\\\\n",
    "index = [1,0,1,0]\n",
    "$$\n",
    "\n",
    "我们用这个$\\alpha$和$index$用做选通网络.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T02:51:47.299418Z",
     "start_time": "2024-06-22T02:51:47.276316Z"
    },
    "id": "jCxoVAx2vBQg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class TopkRouter(nn.Module):\n",
    "    def __init__(self, embed_size, num_experts, active_experts):\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.num_experts = num_experts\n",
    "        self.active_experts = active_experts\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_experts),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs.to(device)\n",
    "        score = self.mlp(inputs)\n",
    "        indices = torch.topk(score, self.active_experts, dim=-1)[1]\n",
    "        mask = torch.zeros_like(score, dtype=torch.bool)\n",
    "        mask.scatter_(dim=-1, index=indices, value=True)\n",
    "\n",
    "        score = score.masked_fill(~mask, float(\"-inf\"))\n",
    "        router_output = F.softmax(score, dim=-1)\n",
    "        router_output = router_output.to(inputs.device)\n",
    "        return router_output, indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6OejgYVCvBQg",
    "tags": []
   },
   "source": [
    "## 稀疏专家网络 SparseMoE\n",
    "\n",
    "![moe](./moeSparse.png)\n",
    "\n",
    "在定义完 Expert 和 TopkRouter 后，我们可以定义 SparseMoE 模块。\n",
    "\n",
    "在前向过程中，对于 inputs.shape = [Batch_size,seq_len,embed_size]第二维度 seq_len 个 Embedding,我们先利用 TopkRouter 计算出选通专家序号 indices 以及专家权重 router_output。\n",
    "\n",
    "我们将 Embedding 通过选通的 Expert 得出 active_expert 个新的 Embedding，然后使用 router_output 的作为权重对新的 Embedding 加权求和作为输出。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T02:51:47.360869Z",
     "start_time": "2024-06-22T02:51:47.354007Z"
    },
    "id": "22w81qg3vBQg"
   },
   "outputs": [],
   "source": [
    "class SparseMoE(nn.Module):\n",
    "    def __init__(self, embed_size: int, num_experts: int, active_experts: int):\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.num_experts = num_experts\n",
    "        self.active_experts = active_experts\n",
    "        self.experts = nn.ModuleList([Expert(embed_size) for _ in range(num_experts)])\n",
    "        self.router = TopkRouter(embed_size, num_experts, active_experts)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        router_output, indices = self.router(inputs)\n",
    "\n",
    "        batch_size, seq_len, _ = inputs.size()\n",
    "        final_output = torch.zeros_like(inputs).to(inputs.device)\n",
    "\n",
    "        for b in range(batch_size):\n",
    "            for s in range(seq_len):\n",
    "                token_inputs = inputs[b, s]\n",
    "\n",
    "                expert_outputs = []\n",
    "                for idx in indices[b, s]:\n",
    "                    output = self.experts[idx](token_inputs.to(inputs.device))\n",
    "                    expert_outputs.append(output)\n",
    "\n",
    "                expert_outputs = torch.stack(expert_outputs).to(inputs.device)\n",
    "                token_router_output = router_output[b, s][indices[b, s]].to(\n",
    "                    inputs.device\n",
    "                )\n",
    "                weighted_sum = torch.sum(\n",
    "                    token_router_output.unsqueeze(-1) * expert_outputs,\n",
    "                    dim=0,\n",
    "                )\n",
    "                final_output[b, s] = weighted_sum\n",
    "\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PZrcAdgqvBQg"
   },
   "source": [
    "Transformer 由一层层的 block 堆叠而成，其中每个 block 的结构从模型的结构图展开中可以看到，由 LayerNorm，Masked multi head attention，(SparseMoE)FeedForward 组成。\n",
    "\n",
    "对于一个表示句子的输入向量 x，其首先会经过 Layer Normalization 层.\n",
    "Layer Normalization 层对于一个 句子个数 x 句子长度 x 单词向量维度 的输入 x, 会在最后两维上进行规范化处理，起到稳定训练的作用。\n",
    "\n",
    "$$\n",
    "LN(x)=\\frac{x-mean(x)}{\\sqrt{var(x)+\\epsilon}}\\cdot\\gamma+\\beta\n",
    "$$\n",
    "\n",
    "其中 mean 和 var 都是在最后两个维度上进行的，layernorm 的实现同学们可以直接调用 nn.LayerNorm\n",
    "经过 layernorm 层后，再经过 Mask multi head attention 层之后，会在+号处再次和原始的输入进行相加，这样的做法能够提高训练的稳定性。有兴趣的同学可以从梯度角度思考原因，或者搜索残差连接相关资料进行学习。\n",
    "之后再同样经过一层 layernorm 和 feedforwad 之后，就可以得到 block 块的输出了。\n",
    "即 x' = x+MHA(LN(x)), y = FFN(LN(x'))+x'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T02:51:47.398133Z",
     "start_time": "2024-06-22T02:51:47.392167Z"
    },
    "id": "vl654g47vBQh"
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_size: int,\n",
    "        n_heads: int,\n",
    "        seq_len: int,\n",
    "        num_experts: int,\n",
    "        active_experts: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.layernorm1 = nn.LayerNorm(embed_size)\n",
    "        self.layernorm2 = nn.LayerNorm(embed_size)\n",
    "        self.attention = MultiHeadAttention(\n",
    "            n_heads, embed_size // n_heads, seq_len, embed_size\n",
    "        )\n",
    "        self.moe = SparseMoE(embed_size, num_experts, active_experts)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.layernorm1(inputs)\n",
    "        x = x + self.attention(x)\n",
    "        x = self.layernorm2(x)\n",
    "        x = x + self.moe(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T02:51:47.439350Z",
     "start_time": "2024-06-22T02:51:47.422351Z"
    },
    "id": "lzKme81ZvBQh"
   },
   "outputs": [],
   "source": [
    "class SparseMoETransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size: int,\n",
    "        seq_len: int,\n",
    "        embed_size: int,\n",
    "        n_layers: int,\n",
    "        n_heads: int,\n",
    "        num_experts: int,\n",
    "        active_experts: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.token_embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.position_embedding = nn.Embedding(seq_len, embed_size)\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [\n",
    "                Block(embed_size, n_heads, seq_len, num_experts, active_experts)\n",
    "                for _ in range(n_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm = nn.LayerNorm(embed_size)\n",
    "        self.output_linear = nn.Linear(embed_size, vocab_size)\n",
    "        nn.init.xavier_uniform_(self.output_linear.weight)\n",
    "\n",
    "    def forward(self, inputs, labels=None):\n",
    "        (batch_size, seq_len,) = inputs.shape\n",
    "\n",
    "        embedding = self.token_embedding(inputs) + self.position_embedding(\n",
    "            torch.arange(seq_len, device=inputs.device)\n",
    "        )\n",
    "\n",
    "        for block in self.blocks:\n",
    "            embedding = block(embedding)\n",
    "\n",
    "        logits = self.output_linear(self.layernorm(embedding))\n",
    "\n",
    "        if labels is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            batch_size, seq_len, vocab_size = logits.shape\n",
    "            logits = logits.view(batch_size * seq_len, vocab_size)\n",
    "            labels = labels.view(batch_size * seq_len)\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, inputs, max_new_tokens):\n",
    "        inputs = tokenizer.encode(inputs).clone().detach().unsqueeze(0)\n",
    "        device = next(self.parameters()).device\n",
    "        inputs = inputs.to(device)\n",
    "        if inputs.size(1) > self.seq_len:\n",
    "            inputs = inputs[:, : self.seq_len]\n",
    "        generated = inputs\n",
    "        for _ in range(max_new_tokens):\n",
    "            if generated.size(1) > self.seq_len:\n",
    "                generated_input = generated[:, -self.seq_len:]\n",
    "            else:\n",
    "                generated_input = generated\n",
    "            logits, _ = self.forward(generated_input)\n",
    "            last_logits = logits[:, -1, :]\n",
    "            next_token_ids = torch.argmax(last_logits, dim=-1)\n",
    "            next_token_ids = next_token_ids.unsqueeze(-1)\n",
    "            generated = torch.cat([generated, next_token_ids], dim=1)\n",
    "            tmp = generated.clone().detach()\n",
    "        return generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWDSdJiVvBQh"
   },
   "source": [
    "# 训练循环\n",
    "\n",
    "如果你已经完成了模型定义等内容，训练的过程实际上在高度封装的 Pytorch 库中非常简单, 因为你并不需要写对应的反向传播。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aARWjavNvBQh"
   },
   "source": [
    "#### Loss\n",
    "\n",
    "Loss 用来**衡量**模型预测与真实值之间的**差距**。\n",
    "\n",
    "常见的几个 Loss 函数：\n",
    "\n",
    "-   交叉熵：$\\text{CrossEntropy Loss} = -\\sum_{i=1}^{n} y_i \\log(\\hat{y}_i)$\n",
    "-   均方误差：$\\text{MSE} = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y_i})^2$\n",
    "-   绝对误差：$\\text{MAE} = \\frac{1}{n}\\sum_{i=1}^{n} |y_i - \\hat{y_i}|$\n",
    "\n",
    "不同的 loss 对应不同的优化目标，如果写错 loss 函数会导致模型不收敛/性能很差。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Mv6xZ-ivBQh"
   },
   "source": [
    "#### 训练循环\n",
    "\n",
    "当我们写好 Optimizer 和 Loss 之后，对应的训练循环就十分简单了。\n",
    "\n",
    "我们只需要做以下事情：\n",
    "\n",
    "-   从 dataloader 里面拿到一个 batch 的数据以及标签\n",
    "-   将数据送入模型，进行前向传播\n",
    "-   拿到模型输出的 logits\n",
    "-   将 logits 和 标签进行 loss 计算\n",
    "-   用 Optimizer\n",
    "    -   清空梯度\n",
    "    -   反向传播\n",
    "    -   更新参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T02:51:47.448623Z",
     "start_time": "2024-06-22T02:51:47.442341Z"
    },
    "id": "TMBFTQjavBQh"
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, epoch, device):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i, (inputs, targets) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        inputs = inputs.clone().detach()\n",
    "        targets = targets.clone().detach()\n",
    "        optimizer.zero_grad()\n",
    "        logits, loss = model(inputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch} Loss: {total_loss / len(dataloader)}\")\n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "\n",
    "def validate(model, dataloader, epoch, device):\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    for i, (inputs, targets) in enumerate(dataloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        logits, loss = model(inputs, targets)\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch} Loss: {total_loss / len(dataloader)}\")\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T03:25:46.518314Z",
     "start_time": "2024-06-22T02:51:47.451533Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4460/4460 [02:13<00:00, 33.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 3.6096951497509875\n",
      "Epoch 0 Loss: 3.289907028643005\n",
      "Epoch 0 Train Loss: 3.6096951497509875, Valid Loss: 3.289907028643005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4460/4460 [02:13<00:00, 33.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 3.2519449356425505\n",
      "Epoch 1 Loss: 3.213034803664203\n",
      "Epoch 1 Train Loss: 3.2519449356425505, Valid Loss: 3.213034803664203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4460/4460 [02:15<00:00, 32.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 3.1659946499918608\n",
      "Epoch 2 Loss: 3.1215896529467115\n",
      "Epoch 2 Train Loss: 3.1659946499918608, Valid Loss: 3.1215896529467115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4460/4460 [02:23<00:00, 31.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 3.082691545657513\n",
      "Epoch 3 Loss: 3.0477690660365493\n",
      "Epoch 3 Train Loss: 3.082691545657513, Valid Loss: 3.0477690660365493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4460/4460 [02:24<00:00, 30.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 3.017548631178424\n",
      "Epoch 4 Loss: 2.9905489134681598\n",
      "Epoch 4 Train Loss: 3.017548631178424, Valid Loss: 2.9905489134681598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4460/4460 [02:20<00:00, 31.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 2.9621864809583656\n",
      "Epoch 5 Loss: 2.927006961839616\n",
      "Epoch 5 Train Loss: 2.9621864809583656, Valid Loss: 2.927006961839616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4460/4460 [01:52<00:00, 39.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 2.89566612890483\n",
      "Epoch 6 Loss: 2.8673643456446216\n",
      "Epoch 6 Train Loss: 2.89566612890483, Valid Loss: 2.8673643456446216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4460/4460 [01:50<00:00, 40.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss: 2.8497401293617726\n",
      "Epoch 7 Loss: 2.829503528740374\n",
      "Epoch 7 Train Loss: 2.8497401293617726, Valid Loss: 2.829503528740374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4460/4460 [01:50<00:00, 40.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss: 2.8155824648959755\n",
      "Epoch 8 Loss: 2.7993782853866374\n",
      "Epoch 8 Train Loss: 2.8155824648959755, Valid Loss: 2.7993782853866374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4460/4460 [01:50<00:00, 40.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Loss: 2.790107076210826\n",
      "Epoch 9 Loss: 2.7771583518639806\n",
      "Epoch 9 Train Loss: 2.790107076210826, Valid Loss: 2.7771583518639806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4460/4460 [01:51<00:00, 40.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Loss: 2.7695147888008256\n",
      "Epoch 10 Loss: 2.7579599532311274\n",
      "Epoch 10 Train Loss: 2.7695147888008256, Valid Loss: 2.7579599532311274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4460/4460 [01:52<00:00, 39.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Loss: 2.7526943296595006\n",
      "Epoch 11 Loss: 2.742855138308264\n",
      "Epoch 11 Train Loss: 2.7526943296595006, Valid Loss: 2.742855138308264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4460/4460 [01:52<00:00, 39.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Loss: 2.7393185983858834\n",
      "Epoch 12 Loss: 2.731073940815947\n",
      "Epoch 12 Train Loss: 2.7393185983858834, Valid Loss: 2.731073940815947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4460/4460 [01:53<00:00, 39.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Loss: 2.72737950391299\n",
      "Epoch 13 Loss: 2.718332995213735\n",
      "Epoch 13 Train Loss: 2.72737950391299, Valid Loss: 2.718332995213735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4460/4460 [01:54<00:00, 38.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Loss: 2.7162564202274444\n",
      "Epoch 14 Loss: 2.7071571277396025\n",
      "Epoch 14 Train Loss: 2.7162564202274444, Valid Loss: 2.7071571277396025\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I could pick my lance t t the the the th the the th the th the th the th the th the th the th the th the th the th the t\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_dataloader, val_dataloader = create_dataloader('input.txt', tokenizer, chunk_size=50, batch_size=512)\n",
    "model = SparseMoETransformer(vocab_size=len(tokenizer.char2index), seq_len=50, embed_size=64, n_layers=1, n_heads=8, num_experts=8, active_experts=2).to(device)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "train_dataloader, val_dataloader = create_dataloader(\n",
    "    \"input.txt\",\n",
    "    tokenizer,\n",
    "    chunk_size=20,\n",
    "    batch_size=10,\n",
    ")\n",
    "model = SparseMoETransformer(\n",
    "    vocab_size=len(tokenizer.char2index),\n",
    "    seq_len=20,\n",
    "    embed_size=4,\n",
    "    n_layers=1,\n",
    "    n_heads=1,\n",
    "    num_experts=2,\n",
    "    active_experts=1,\n",
    ").to(device)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "def run(model, train_dataloader, valid_dataloader, device, epochs=0):\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train(model, train_dataloader, epoch, device)\n",
    "        valid_loss = validate(model, valid_dataloader, epoch, device)\n",
    "        print(f\"Epoch {epoch} Train Loss: {train_loss}, Valid Loss: {valid_loss}\")\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "    return train_losses, valid_losses\n",
    "\n",
    "\n",
    "def plot_loss(train_loss, valid_loss):\n",
    "    plt.plot(train_loss, label=\"train loss\")\n",
    "    plt.plot(valid_loss, label=\"valid loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "train_losses, valid_losses = run(\n",
    "    model, train_dataloader, val_dataloader, device, epochs=15\n",
    ")\n",
    "plot_loss(train_losses, valid_losses)\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "\n",
    "print(\n",
    "    tokenizer.decode(\n",
    "        model.generate(\"I could pick my lance\", max_new_tokens=100)[0].tolist()\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
